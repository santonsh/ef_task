{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading to dataframe\n",
    "# Creating additional columns\n",
    "gen = ((k, v['assetA']['bid'], v['assetA']['ask'], v['assetB']['bid'], v['assetB']['ask']) for k, v in data.items())\n",
    "data_list = [x for x in gen]\n",
    "df = pd.DataFrame(data_list, columns=['timestamp', 'assetA_bid', 'assetA_ask', 'assetB_bid', 'assetB_ask'])\n",
    "df['delta_t'] = df['timestamp'].astype('uint64').diff()\n",
    "df['trade_freq'] = df.apply (lambda row: 1/row['delta_t'], axis=1)\n",
    "df['trade_freq_avg'] = df['trade_freq'].rolling(window=15).mean()\n",
    "df = df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x24eb8418c10>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Lets chart some analytics - trade frequency, tick frequency\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig0, (ax00, ax01) = plt.subplots(2, 1)\n",
    "ax00.set_title('Tick time delta histogram (up to 2 seconds)')\n",
    "ax01.set_title('Tick time delta averaged in time')\n",
    "df['delta_t'].hist(ax = ax00, bins = np.arange(10,2000,100))\n",
    "df['delta_t'].rolling(window=30).mean().rolling(window=30).mean().rolling(window=30).mean().plot(ax = ax01)\n",
    "\n",
    "# Conclutions:\n",
    "# 1. the samples are highlty uneaven with rare time deltas up to several minutes. Most time deltas between the samples however are between 50 and 500 ms\n",
    "# 2. Due to (1) several approaches can be taked to fight non uniformity of samples\n",
    "#   a. upsample missing timepoints\n",
    "#   b. craete new more uniform ticks by special transformation (time, volume, cumulative price ticks or entropy based ticks)\n",
    "#   c. train predictor in such a way that accounts for timme deltas between samples\n",
    "#   d. assume low impact of non uniformity and treat as uniform (probably a bad idea but will do for start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The time period is: Float64Index([1.083294814814815], dtype='float64', name='timestamp') days\nMaximum possible trades in this period is: Float64Index([3119.889066666667], dtype='float64', name='timestamp') trades\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Text(0.5, 1.0, 'B Signals zoomin')"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Plot the ask/bid data for analysis\n",
    "# Get the timeline data \n",
    "start = df.iloc[[0]].index.astype('uint64')\n",
    "end = df.iloc[[-1]].index.astype('uint64')\n",
    "timedelta = end-start\n",
    "print(f'The time period is: {timedelta/1000/60/60/24} days')\n",
    "print(f'Maximum possible trades in this period is: {timedelta/1000/30} trades')\n",
    "\n",
    "# Setting up the grids\n",
    "delta_t = end.to_numpy()-start.to_numpy()\n",
    "number_of_ticks = len(df)\n",
    "minor_grid_min = 0.5\n",
    "ticksPerHour = number_of_ticks/(delta_t/1000/60/60)\n",
    "ticksPerMinorGrid = number_of_ticks/(delta_t/1000/60)*minor_grid_min\n",
    "\n",
    "hour_grid = np.arange(-0.2*number_of_ticks, 1.2*number_of_ticks, ticksPerHour)\n",
    "minor_grid = np.arange(-0.2*number_of_ticks, 1.2*number_of_ticks, ticksPerMinorGrid)\n",
    "\n",
    "# Plot the next graphs:\n",
    "# Subplot 1\n",
    "# a. A spread\n",
    "# b. B spread\n",
    "# c. A ask and bid\n",
    "# c. B ask and bid\n",
    "\n",
    "SpreadA = df['assetA_ask'].sub(df['assetA_bid'])\n",
    "SpreadB = df['assetB_ask'].sub(df['assetB_bid'])\n",
    "bidA = df['assetA_bid']\n",
    "askA = df['assetA_ask']\n",
    "bidB = df['assetB_bid']\n",
    "askB = df['assetB_ask']\n",
    "\n",
    "fig1, (ax10, ax11, ax12) = plt.subplots(3, 1)\n",
    "#ax10.set_xticks(hour_grid)\n",
    "#ax10.set_xticks(minor_grid, minor=True)\n",
    "#ax10.grid(which='both')\n",
    "\n",
    "for sig in [bidA, askA, bidB, askB]:\n",
    "    sig_scaled = sig-7050\n",
    "    sig_scaled.plot(ax = ax10)\n",
    "    sig_scaled.rolling(window=30).mean().plot(ax = ax10, style=':')\n",
    "\n",
    "i = -20\n",
    "for sig in [SpreadA, SpreadB]:\n",
    "    i=i+20\n",
    "    sig_scaled = sig*5+i # Just a scaling to fit on one axes\n",
    "    sig_scaled.plot(ax = ax10)\n",
    "    sig_scaled.rolling(window=30).mean().plot(ax = ax10, style=':')\n",
    "\n",
    "ax10.legend(['bidA', 'bidA avg', 'askA', 'askA avg', 'bidB', 'bidB avg', 'askB', 'askB avg', 'SpreadA', 'SpreadA avg', 'SpreadB', 'SpreadB avg'])\n",
    "ax10.set_title('A and B ask/bid and spread')\n",
    "\n",
    "# Subplot 2\n",
    "# a. A ask and bid zoomin\n",
    "\n",
    "zoomin_range = np.arange(4000,5000,1)\n",
    "\n",
    "for sig in [bidA, askA]:\n",
    "    sig.iloc[zoomin_range].plot(ax = ax11)\n",
    "    sig_mov = sig.rolling(window=30).mean()\n",
    "    sig_mov.iloc[zoomin_range].plot(ax = ax11, style=':')\n",
    "    sig.iloc[zoomin_range].plot(ax = ax11, style = '.')\n",
    "\n",
    "ax11.legend(['bidA', 'bidA avg', 'bidA scatter', 'askA', 'askA avg', 'askA scatter'])\n",
    "ax11.set_title('A Signals zoomin')\n",
    "\n",
    "# Subplot 3\n",
    "# a. B ask and bid zoomin \n",
    "\n",
    "for sig in [bidB, askB]:\n",
    "    sig.iloc[zoomin_range].plot(ax = ax12)\n",
    "    sig_mov = sig.rolling(window=30).mean()\n",
    "    sig_mov.iloc[zoomin_range].plot(ax = ax12, style=':')\n",
    "    sig.iloc[zoomin_range].plot(ax = ax12, style = '.')\n",
    "\n",
    "ax12.legend(['bidB', 'bidB avg', 'bidB scatter', 'askB', 'askB avg', 'askB scatter'])\n",
    "ax12.set_title('B Signals zoomin')\n",
    "\n",
    "# Conclutions:\n",
    "# 1. Zoomout: \n",
    "#   a. The trading dataframe is of one day aproximately\n",
    "#   b. A and B are hightly correlated at least at low resolution\n",
    "#   c. There are negative spreads in the data up to tens of seconds. Three of possible explanations are \n",
    "#       i. Bullish of Bearish trades beyond optimal opposite price point \n",
    "#       ii. missing data points/lags in an order book that creates opposite price optimization lag\n",
    "#       iii. Lagging price correction \n",
    "\n",
    "# 2. Zoomin\n",
    "#   a. Uneven sampling can be seen\n",
    "#   b. A and B have different trading dynamics\n",
    "#   c. A and B have different spread\n",
    "#   d. A and B have different trading patterns\n",
    "#   e. As a result of (b), (c), and (d) we can deduct different number of traders, hightly different volumes traded for assets A ndd B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ask/bid data analitics\n",
    "\n",
    "fig2, (ax20, ax21, ax22) = plt.subplots(3, 1)\n",
    "\n",
    "# Subplot 1\n",
    "# a. A trailing window var\n",
    "# b. B trailing window var\n",
    "\n",
    "ax20.set_title('Rolling window signal variance')\n",
    "\n",
    "i=0\n",
    "for sig in [bidA, askA, bidB, askB]:\n",
    "    i=i+10\n",
    "    sig_mov = sig.rolling(window=30).var()+i\n",
    "    sig_mov.plot(ax = ax20)\n",
    "\n",
    "ax20.legend(['bidA var', 'askA var','bidB var', 'askB var'])\n",
    "ax20.get_xaxis().set_visible(False)\n",
    "\n",
    "# Subplot 2\n",
    "# a. ask/bid trailing window cov\n",
    "\n",
    "ax21.set_title('Rolling window ask/bid covariance')\n",
    "cov_A = bidA.rolling(window=30).cov(other = askA)+10\n",
    "cov_B = bidB.rolling(window=30).cov(other = askB)-10\n",
    "cov_A.plot(ax = ax21)\n",
    "cov_B.plot(ax = ax21)\n",
    "ax21.legend(['A bid/ask cov', 'B bid/ask cov'])\n",
    "ax21.get_xaxis().set_visible(False)\n",
    "\n",
    "# Subplot 3\n",
    "# a. AB trailing window cov\n",
    "\n",
    "ax22.set_title('Rolling window A/B covariance')\n",
    "cov_bid = bidA.rolling(window=30).cov(other = bidB)+10\n",
    "cov_ask = askA.rolling(window=30).cov(other = askB)-10\n",
    "cov_bid.plot(ax = ax22)\n",
    "cov_ask.plot(ax = ax22)\n",
    "ax22.legend(['A/B bid cov', 'A/B ask cov'])\n",
    "ax22.get_xaxis().set_visible(False)\n",
    "\n",
    "# Conclutions:\n",
    "#   a. Hmmmm... Not sure what can be seen here at low resolution in regard of var/covar between signals. \n",
    "#   b. Peaks in A/B and bid/ask covariance correlates to occations of magor trading (volume, price change) likely (?)\n",
    "#   c. var and covar graphs for all the signals look alike which probably reflect the fact that assets are closely related. Especially it shows at major trading periods (spikes in var/covar) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class silding_window():\n",
    "# base class for sliding window functions \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.arr = []\n",
    "        self.val = None\n",
    "        self.last = None\n",
    "\n",
    "    def update(self, val):\n",
    "        if val == None:\n",
    "            val = self.last\n",
    "        self.last = val\n",
    "        if len(self.arr) == self.size:\n",
    "            self.arr.pop(0)\n",
    "            self.arr.append(val)\n",
    "            self.val = self.func()\n",
    "            return\n",
    "\n",
    "        self.arr.append(val)\n",
    "\n",
    "    def getval(self):\n",
    "        return self.val\n",
    "\n",
    "    def next_tick(self, val):\n",
    "        self.update(val)\n",
    "        return self.getval\n",
    "\n",
    "    def func(self):\n",
    "    # This function is to be rewritten in downstream classees\n",
    "        return None\n",
    "\n",
    "class avg_silding_window(silding_window):\n",
    "# mooving average class\n",
    "    def func(self):\n",
    "        return np.mean(self.arr)\n",
    "\n",
    "def lookAheadTradeReturnPredictorFunc(pred, active_asset):\n",
    "    # Input:\n",
    "    #   Array of [K x 2N] (2 * trading delay) prices predictions for K assets\n",
    "    # Output:\n",
    "    #   [K x N] Array of minimal return predictions for each of next N ticks (1*trading delay delta) for each asset\n",
    "    # Note: later to each element of future return predictions in non active asset the delta of active asset for the preceeding period should be added to account for a price of not taking a trading action \n",
    "    # Note: Each of the points in the array answers the question \"what would be my return after minimal trading delay if I choose to go into asset k at timepoint 0<=n<N\". Why so many optional point n instead of just a single time point in the present? Because by being gridy we are risking missing the \"good\" trade point in the nearest future because of the introduced trading delay   \n",
    "    # A1 [1   2 3 1  3 1 3  4 4 23 32  32 34 ]\n",
    "    # A2 [-1 -2 3 1 -3 1 3 -4 4 2  12 -12 14 ]\n",
    "    # Note: How the trade return is calculated? At tick 0<=n<N asset price (buy - active asset is an exception) is taken and substracted from the price (sell) at point n'=n+N (Next nearest possible trade)\n",
    "    pass\n",
    "\n",
    "def lookAheadTradeDescitionMakerFunc(return_pred, greediness_w ):\n",
    "    # Input:\n",
    "    # [K x N] trading return predictions array\n",
    "    # [N] Greediness vector. This is a vector that favors the earlier trades by multiplying the predicted returns vector for each asset. This is to caount for time value lost in delayed trades and rising uncertanty for farther predictions\n",
    "    # Output:\n",
    "    # (asset_idx, min_return) Returns index of asset with best predicted return and the predicted return itself \n",
    "    pass\n",
    "class idealPredictor():\n",
    "    def __init__(self, df, lookahead):\n",
    "        self.df = df\n",
    "        self.lookahead = lookahead\n",
    "\n",
    "    def predict(self, ts):\n",
    "        print(df.loc[ts])\n",
    "        self\n",
    "\n",
    "class tradingBot():\n",
    "    # Note: \n",
    "    # Simple bot scheme\n",
    "    # bare_signals -> features -> price_prediction  -> trade_orders  \n",
    "    #                                     strategy  ->\n",
    "    def __init__(self, predictor, qty = 100, trading_delay = 30):\n",
    "        self.last_trade = None\n",
    "        self.trading_delay = trading_delay \n",
    "        self.orders = []\n",
    "        self.last_order = {}\n",
    "        self.cur_asset_id = 0\n",
    "        self.cur_qty = qty\n",
    "        self.cur_ts = 0\n",
    "        self.predictor = predictor\n",
    "\n",
    "        \n",
    "    def compute_tick(self, ts, data):\n",
    "        # this handles new data arriving to the bot\n",
    "        # done\n",
    "        self.append_data(data)\n",
    "        self.pred = self.predictor.update(data)\n",
    "        self.cur_ts = ts\n",
    "        if (ts-self.last_trade) > self.trading_delay*1000:\n",
    "            self.pred = self.predictor.get_pred()\n",
    "            new_asset_id = self.compute_trade()\n",
    "            self.update_state(new_asset_id)\n",
    "\n",
    "    def append_data(self, data):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def compute_trade(self):\n",
    "        # this computes trade based on the current market\n",
    "        return_pred = self.doReturnCalculation(self.pred)\n",
    "        (asset_id, ret) = self.makeDescition(return_pred)\n",
    "        return asset_id\n",
    "\n",
    "    def update_state(self, tgt_asset_id):\n",
    "        # this updates bot state based on target asset_id\n",
    "        # done\n",
    "        if tgt_asset_id != self.cur_asset_id:\n",
    "            if self.cur_asset_id == 0:\n",
    "                self.issue_trades([('Buy', tgt_asset_id)])\n",
    "            elif tgt_asset_id == 0:\n",
    "                self.issue_trades([('Sell', self.cur_asset_id)])\n",
    "            else:\n",
    "                self.issue_trades([('Sell', self.cur_asset_id), ('Buy', tgt_asset_id)])\n",
    "    \n",
    "    def issue_trades(orders):\n",
    "        # done\n",
    "        actions = []\n",
    "        for (order_type, asset_id) in orders:\n",
    "            # update the quantities and asset stocks\n",
    "            if order_type == 'Sell':\n",
    "                self.qty = self.qty*get_sell_price(asset_id)\n",
    "                self.asset_id = 0\n",
    "            elif order_type == 'Buy':\n",
    "                self.asset_id = asset_id\n",
    "                self.qty = self.qty/self.get_buy_price(asset_id)\n",
    "            # update the orders\n",
    "            actions.append(order_type+str(asset_id))\n",
    "            \n",
    "        # update an order book\n",
    "        self.orders.append({\n",
    "                \"time\": self.cur_ts,\n",
    "                \"actions\": actions\n",
    "                })\n",
    "\n",
    "    def get_sell_price(self, asset_id):\n",
    "        # DONOTFORGET\n",
    "        return 1\n",
    "    def get_buy_price(self, asset_id):\n",
    "        # DONOTFORGET\n",
    "        return 1\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'1577836806372'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1577836806372'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-370aed9734e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midealPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(df.head(3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1577836806372'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-c1bb4e0632aa>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, ts)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1965\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3536\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3537\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3539\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aifml\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1577836806372'"
     ]
    }
   ],
   "source": [
    "p = idealPredictor(df, 50)\n",
    "#print(df.head(3))\n",
    "p.predict(1577836806371)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e228bda22254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mtick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_tick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#print(t['assets']['assetA']['ask'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def read_tick(df):\n",
    "    for i, row in df.iterrows():\n",
    "        tick = {    'timestamp':'next_tick',\n",
    "                    'assets':{\n",
    "                                'assetA':{\n",
    "                                            'ask':row['assetA_ask'],\n",
    "                                            'bid':row['assetA_bid']\n",
    "                                        }, \n",
    "                                'assetB':{\n",
    "                                            'ask':row['assetB_ask'],\n",
    "                                            'bid':row['assetB_bid']\n",
    "                                        }\n",
    "                    }\n",
    "                }\n",
    "        yield tick\n",
    "\n",
    "for t in read_tick(df):\n",
    "    pass\n",
    "    #print(t['assets']['assetA']['ask'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}