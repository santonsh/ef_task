{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "with open('data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading to dataframe\n",
    "# Creating additional columns\n",
    "gen = ((k, v['assetA']['bid'], v['assetA']['ask'], v['assetB']['bid'], v['assetB']['ask']) for k, v in data.items())\n",
    "data_list = [x for x in gen]\n",
    "df = pd.DataFrame(data_list, columns=['timestamp', 'assetA_bid', 'assetA_ask', 'assetB_bid', 'assetB_ask'])\n",
    "df['delta_t'] = df['timestamp'].astype('uint64').diff()\n",
    "df['trade_freq'] = df.apply (lambda row: 1/row['delta_t'], axis=1)\n",
    "df['trade_freq_avg'] = df['trade_freq'].rolling(window=15).mean()\n",
    "df['ts'] = df['timestamp']\n",
    "df = df.set_index('timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x24f7acd1ca0>"
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "source": [
    "# Lets chart some analytics - trade frequency, tick frequency\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig0, (ax00, ax01) = plt.subplots(2, 1)\n",
    "ax00.set_title('Tick time delta histogram (up to 2 seconds)')\n",
    "ax01.set_title('Tick time delta averaged in time')\n",
    "df['delta_t'].hist(ax = ax00, bins = np.arange(10,2000,100))\n",
    "df['delta_t'].rolling(window=30).mean().rolling(window=30).mean().rolling(window=30).mean().plot(ax = ax01)\n",
    "\n",
    "# Conclutions:\n",
    "# 1. the samples are highlty uneaven with rare time deltas up to several minutes. Most time deltas between the samples however are between 50 and 500 ms\n",
    "# 2. Due to (1) several approaches can be taked to fight non uniformity of samples\n",
    "#   a. upsample missing timepoints\n",
    "#   b. craete new more uniform ticks by special transformation (time, volume, cumulative price ticks or entropy based ticks)\n",
    "#   c. train predictor in such a way that accounts for timme deltas between samples\n",
    "#   d. assume low impact of non uniformity and treat as uniform (probably a bad idea but will do for start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The time period is: Float64Index([1.083294814814815], dtype='float64', name='timestamp') days\nMaximum possible trades in this period is: Float64Index([3119.889066666667], dtype='float64', name='timestamp') trades\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Text(0.5, 1.0, 'B Signals zoomin')"
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "# Plot the ask/bid data for analysis\n",
    "# Get the timeline data \n",
    "start = df.iloc[[0]].index.astype('uint64')\n",
    "end = df.iloc[[-1]].index.astype('uint64')\n",
    "timedelta = end-start\n",
    "print(f'The time period is: {timedelta/1000/60/60/24} days')\n",
    "print(f'Maximum possible trades in this period is: {timedelta/1000/30} trades')\n",
    "\n",
    "# Setting up the grids\n",
    "delta_t = end.to_numpy()-start.to_numpy()\n",
    "number_of_ticks = len(df)\n",
    "minor_grid_min = 0.5\n",
    "ticksPerHour = number_of_ticks/(delta_t/1000/60/60)\n",
    "ticksPerMinorGrid = number_of_ticks/(delta_t/1000/60)*minor_grid_min\n",
    "\n",
    "hour_grid = np.arange(-0.2*number_of_ticks, 1.2*number_of_ticks, ticksPerHour)\n",
    "minor_grid = np.arange(-0.2*number_of_ticks, 1.2*number_of_ticks, ticksPerMinorGrid)\n",
    "\n",
    "# Plot the next graphs:\n",
    "# Subplot 1\n",
    "# a. A spread\n",
    "# b. B spread\n",
    "# c. A ask and bid\n",
    "# c. B ask and bid\n",
    "\n",
    "SpreadA = df['assetA_ask'].sub(df['assetA_bid'])\n",
    "SpreadB = df['assetB_ask'].sub(df['assetB_bid'])\n",
    "bidA = df['assetA_bid']\n",
    "askA = df['assetA_ask']\n",
    "bidB = df['assetB_bid']\n",
    "askB = df['assetB_ask']\n",
    "\n",
    "fig1, (ax10, ax11, ax12) = plt.subplots(3, 1)\n",
    "#ax10.set_xticks(hour_grid)\n",
    "#ax10.set_xticks(minor_grid, minor=True)\n",
    "#ax10.grid(which='both')\n",
    "\n",
    "for sig in [bidA, askA, bidB, askB]:\n",
    "    sig_scaled = sig-7050\n",
    "    sig_scaled.plot(ax = ax10)\n",
    "    sig_scaled.rolling(window=30).mean().plot(ax = ax10, style=':')\n",
    "\n",
    "i = -20\n",
    "for sig in [SpreadA, SpreadB]:\n",
    "    i=i+20\n",
    "    sig_scaled = sig*5+i # Just a scaling to fit on one axes\n",
    "    sig_scaled.plot(ax = ax10)\n",
    "    sig_scaled.rolling(window=30).mean().plot(ax = ax10, style=':')\n",
    "\n",
    "ax10.legend(['bidA', 'bidA avg', 'askA', 'askA avg', 'bidB', 'bidB avg', 'askB', 'askB avg', 'SpreadA', 'SpreadA avg', 'SpreadB', 'SpreadB avg'])\n",
    "ax10.set_title('A and B ask/bid and spread')\n",
    "\n",
    "# Subplot 2\n",
    "# a. A ask and bid zoomin\n",
    "\n",
    "zoomin_range = np.arange(4000,5000,1)\n",
    "\n",
    "for sig in [bidA, askA]:\n",
    "    sig.iloc[zoomin_range].plot(ax = ax11)\n",
    "    sig_mov = sig.rolling(window=30).mean()\n",
    "    sig_mov.iloc[zoomin_range].plot(ax = ax11, style=':')\n",
    "    sig.iloc[zoomin_range].plot(ax = ax11, style = '.')\n",
    "\n",
    "ax11.legend(['bidA', 'bidA avg', 'bidA scatter', 'askA', 'askA avg', 'askA scatter'])\n",
    "ax11.set_title('A Signals zoomin')\n",
    "\n",
    "# Subplot 3\n",
    "# a. B ask and bid zoomin \n",
    "\n",
    "for sig in [bidB, askB]:\n",
    "    sig.iloc[zoomin_range].plot(ax = ax12)\n",
    "    sig_mov = sig.rolling(window=30).mean()\n",
    "    sig_mov.iloc[zoomin_range].plot(ax = ax12, style=':')\n",
    "    sig.iloc[zoomin_range].plot(ax = ax12, style = '.')\n",
    "\n",
    "ax12.legend(['bidB', 'bidB avg', 'bidB scatter', 'askB', 'askB avg', 'askB scatter'])\n",
    "ax12.set_title('B Signals zoomin')\n",
    "\n",
    "# Conclutions:\n",
    "# 1. Zoomout: \n",
    "#   a. The trading dataframe is of one day aproximately\n",
    "#   b. A and B are hightly correlated at least at low resolution\n",
    "#   c. There are negative spreads in the data up to tens of seconds. Three of possible explanations are \n",
    "#       i. Bullish of Bearish trades beyond optimal opposite price point \n",
    "#       ii. missing data points/lags in an order book that creates opposite price optimization lag\n",
    "#       iii. Lagging price correction \n",
    "\n",
    "# 2. Zoomin\n",
    "#   a. Uneven sampling can be seen\n",
    "#   b. A and B have different trading dynamics\n",
    "#   c. A and B have different spread\n",
    "#   d. A and B have different trading patterns\n",
    "#   e. As a result of (b), (c), and (d) we can deduct different number of traders, hightly different volumes traded for assets A ndd B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ask/bid data analitics\n",
    "\n",
    "fig2, (ax20, ax21, ax22) = plt.subplots(3, 1)\n",
    "\n",
    "# Subplot 1\n",
    "# a. A trailing window var\n",
    "# b. B trailing window var\n",
    "\n",
    "ax20.set_title('Rolling window signal variance')\n",
    "\n",
    "i=0\n",
    "for sig in [bidA, askA, bidB, askB]:\n",
    "    i=i+10\n",
    "    sig_mov = sig.rolling(window=30).var()+i\n",
    "    sig_mov.plot(ax = ax20)\n",
    "\n",
    "ax20.legend(['bidA var', 'askA var','bidB var', 'askB var'])\n",
    "ax20.get_xaxis().set_visible(False)\n",
    "\n",
    "# Subplot 2\n",
    "# a. ask/bid trailing window cov\n",
    "\n",
    "ax21.set_title('Rolling window ask/bid covariance')\n",
    "cov_A = bidA.rolling(window=30).cov(other = askA)+10\n",
    "cov_B = bidB.rolling(window=30).cov(other = askB)-10\n",
    "cov_A.plot(ax = ax21)\n",
    "cov_B.plot(ax = ax21)\n",
    "ax21.legend(['A bid/ask cov', 'B bid/ask cov'])\n",
    "ax21.get_xaxis().set_visible(False)\n",
    "\n",
    "# Subplot 3\n",
    "# a. AB trailing window cov\n",
    "\n",
    "ax22.set_title('Rolling window A/B covariance')\n",
    "cov_bid = bidA.rolling(window=30).cov(other = bidB)+10\n",
    "cov_ask = askA.rolling(window=30).cov(other = askB)-10\n",
    "cov_bid.plot(ax = ax22)\n",
    "cov_ask.plot(ax = ax22)\n",
    "ax22.legend(['A/B bid cov', 'A/B ask cov'])\n",
    "ax22.get_xaxis().set_visible(False)\n",
    "\n",
    "# Conclutions:\n",
    "#   a. Hmmmm... Not sure what can be seen here at low resolution in regard of var/covar between signals. \n",
    "#   b. Peaks in A/B and bid/ask covariance correlates to occations of magor trading (volume, price change) likely (?)\n",
    "#   c. var and covar graphs for all the signals look alike which probably reflect the fact that assets are closely related. Especially it shows at major trading periods (spikes in var/covar) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##################################################################\n",
    "###############    Trading bot\n",
    "##################################################################\n",
    "\n",
    "# A simple trading system can be sketched as this:\n",
    "# (A) marketInputs -> (B) features/signals -> (C) assetPredictions [t, price, prob] -> (D) portfolioOtimization -> (E) orders\n",
    "\n",
    "# For (A) we have our initial signals\n",
    "\n",
    "# For (B) we can generate new features like trading frequency, volume, signal variance. In general case this can include outside signals like semantic market analysis or other exchanges data. \n",
    "\n",
    "# For (C) possibilities are wast. The predictor can be short termed, long termed, tech analysis based, ML/NN based. In this assignment we will check 3 options for the predictor:\n",
    "#   a. Ideal predictor. The predictor that knows the future exactly. Built by using existing dataframe. It is good for initial debug and as a performance reference for other predictors\n",
    "#   b. overfitted NN predictor. We will train the NN on the entire dataframe and use it on the same dataframe in inference mode for trading. It is not a fair predictor as it uses information from the future for learning. However it can be used as a refeerence for future predictors\n",
    "#   c. NN predictor that is trained on a past window and is used for some time until the model get updated with new data. \n",
    "\n",
    "# For (D) we will use a strategy that chooses to maximize predicted return on portfolio. For the sake of assignment we assume oreders of 1 only so we will not create risk-return optimized and distributed portfolios. In real world however it is a good idea to predict prices/signals/returns with probabilities and use them to maintain return-risk optimized portfolios be choosing assets to be close to efficiency frontier. \n",
    "\n",
    "# (E) Orders should be of size of one every time and spaced at least 30 seconds each\n",
    "\n",
    "\n",
    "# Lets start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class silding_window():\n",
    "# base class for sliding window functions \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.arr = []\n",
    "        self.val = None\n",
    "        self.last = None\n",
    "\n",
    "    def update(self, val):\n",
    "        if val == None:\n",
    "            val = self.last\n",
    "        self.last = val\n",
    "        if len(self.arr) == self.size:\n",
    "            self.arr.pop(0)\n",
    "            self.arr.append(val)\n",
    "            self.val = self.func()\n",
    "            return\n",
    "\n",
    "        self.arr.append(val)\n",
    "\n",
    "    def getval(self):\n",
    "        return self.val\n",
    "\n",
    "    def next_tick(self, val):\n",
    "        self.update(val)\n",
    "        return self.getval\n",
    "\n",
    "    def func(self):\n",
    "    # This function is to be rewritten in downstream classees\n",
    "        return None\n",
    "\n",
    "class avg_silding_window(silding_window):\n",
    "# mooving average class\n",
    "    def func(self):\n",
    "        return np.mean(self.arr)\n",
    "\n",
    "def lookAheadTradeReturnPredictorFunc(pred, active_asset, N):\n",
    "    # Input:\n",
    "    #   Array of [K x 2N] (2 * trading delay) prices predictions for K assets\n",
    "    # Output:\n",
    "    #   [K x N] Array of minimal return predictions for each of next N ticks (1*trading delay delta) for each asset\n",
    "    # Note: later to each element of future return predictions in non active asset the delta of active asset for the preceeding period should be added to account for a price of not taking a trading action \n",
    "    # Note: Each of the points in the array answers the question \"what would be my return after minimal trading delay if I choose to go into asset k at timepoint 0<=n<N\". Why so many optional point n instead of just a single time point in the present? Because by being gridy we are risking missing the \"good\" trade point in the nearest future because of the introduced trading delay   \n",
    "    # A1 [1   2 3 1  3 1 3  4 4 23 32  32 34 ]\n",
    "    # A2 [-1 -2 3 1 -3 1 3 -4 4 2  12 -12 14 ]\n",
    "    # Note: How the trade return is calculated? At tick 0<=n<N asset price[buy/ask] (active asset is an exception) is taken and substracted from the sell/bid price at point n'=n+N (Next nearest possible trade)\n",
    "    \n",
    "    try:\n",
    "        # first compute the return of active asset up to timepoint n if no decicion is made now at n=0\n",
    "        if active_asset != -1 and active_asset < len(pred):\n",
    "            bid = pred[active_asset][1]\n",
    "            aa_ret_up_to_n = [bid[i]-bid[0] for i in range(0,N)]\n",
    "        else:\n",
    "            # no active asset means no return on it\n",
    "            aa_ret_up_to_n = [0 for i in range(0,N)]\n",
    "\n",
    "        returns = []\n",
    "        for asset, data in enumerate(pred):\n",
    "            [ask, bid] = data\n",
    "            ret = []\n",
    "            if asset == active_asset:\n",
    "                for n in range(0,N):\n",
    "                    r = bid[n+N] - bid[n] + aa_ret_up_to_n[n] # if asset is active then we dont have to buy it hence bid instead of ask\n",
    "                    ret.append(r)\n",
    "            else:\n",
    "                for n in range(0,N):\n",
    "                    r = bid[n+N] - ask[n] + aa_ret_up_to_n[n]\n",
    "                    ret.append(r)\n",
    "            returns.append(ret)\n",
    "        return returns\n",
    "    except: # in case of too short prediction vector for example\n",
    "        return []\n",
    "\n",
    "def lookAheadTradeDescitionMakerFunc(return_pred, greediness_w ):\n",
    "    # Input:\n",
    "    # [K x N] trading return predictions array\n",
    "    # [N] Greediness vector. This is a vector that favors the earlier trades by multiplying the predicted returns vector for each asset. This is to caount for time value lost in delayed trades and rising uncertanty for farther predictions\n",
    "    # Output:\n",
    "    # (asset_idx, min_return) Returns index of asset with best predicted return and the predicted return itself \n",
    "    max_asset = -1\n",
    "    max_return = 0\n",
    "    max_time = 0\n",
    "    for asset, ret in enumerate(return_pred):\n",
    "        # weight the trading delay\n",
    "        for i in range(len(ret)):\n",
    "            ret[i] = ret[i]*greediness_w[i]\n",
    "        # find the max for this asset return    \n",
    "        m = max(ret)\n",
    "        if m > max_return:\n",
    "            max_return = m\n",
    "            max_asset = asset\n",
    "            max_time = ret.index(m)\n",
    "\n",
    "    return (max_return, max_asset, max_time)\n",
    "\n",
    "class idealPredictor():\n",
    "    # This just looks into the future of dataframe\n",
    "    def __init__(self, df, cols, lookahead):\n",
    "        self.df = df\n",
    "        self.lookahead = lookahead\n",
    "        self.cols = cols\n",
    "    \n",
    "    def update(self, data):\n",
    "        pass\n",
    "\n",
    "    def predict(self, ts):\n",
    "        try:\n",
    "            its = df.index.get_loc(ts)\n",
    "            sub_df = df.iloc[its:its+self.lookahead][self.cols]\n",
    "            pred = []\n",
    "            for c in self.cols:\n",
    "                pred.append(sub_df[c].to_numpy())\n",
    "            return pred\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "class tradingBot():\n",
    "    # Note: \n",
    "    # Simple bot scheme\n",
    "    # bare_signals -> features -> price_prediction  -> trade_orders  \n",
    "    #                                     strategy  ->\n",
    "    def __init__(self, asset_names, trading_delay, ticks_per_trade_delay, predictor, calcRetFunc, calcDescisionFunc ):\n",
    "        self.last_trade = 0\n",
    "        self.trading_delay = trading_delay \n",
    "        self.orders = []\n",
    "        self.last_order = {}\n",
    "        self.cur_asset_id = -1\n",
    "        self.cur_qty = 0\n",
    "        self.cur_ts = 0\n",
    "        self.N = ticks_per_trade_delay\n",
    "        self.predictor = predictor\n",
    "        self.calcRetFunc = calcRetFunc\n",
    "        self.calcDescisionFunc = calcDescisionFunc\n",
    "        self.greediness_w = [1 for i in range(self.N)]\n",
    "        self.last_data = []\n",
    "        self.asset_names = asset_names\n",
    "\n",
    "        \n",
    "    def compute_tick(self, ts, data):\n",
    "        # this handles new data arriving to the bot\n",
    "        # done\n",
    "        self.append_data(data)\n",
    "        self.pred = self.predictor.update(data)\n",
    "        self.cur_ts = ts\n",
    "        # perform action if enough time passed since last action\n",
    "        if (int(ts)-int(self.last_trade)) > self.trading_delay*1000:\n",
    "            pred = self.predictor.predict(self.cur_ts)\n",
    "            # convert prediction signals to ask/bid pairs list: [[askA, bidA], [askB, bidB]..... ]\n",
    "            self.pred = [[pred[2*i], pred[2*i+1]] for i in range(int(len(pred)/2))]\n",
    "            new_asset_id = self.compute_trade()\n",
    "            self.update_state(new_asset_id)\n",
    "\n",
    "    def append_data(self, data):\n",
    "        # EXTEND LATER\n",
    "        self.last_data = data\n",
    "        #for asset, val in items(data):\n",
    "        pass\n",
    "\n",
    "    def compute_trade(self):\n",
    "        # this computes trade based on the current market\n",
    "        return_pred = self.calcRetFunc(self.pred, self.cur_asset_id, self.N)\n",
    "        # kinda error handling - REFACTOR!!!\n",
    "        if return_pred == []:\n",
    "            return self.cur_asset_id\n",
    "        (expected_ret, asset_id, trade_time) = self.calcDescisionFunc(return_pred, self.greediness_w)\n",
    "        # if the optimum in the future skip the trade\n",
    "        if trade_time>0:\n",
    "            return self.cur_asset_id\n",
    "        return asset_id\n",
    "\n",
    "    def update_state(self, tgt_asset_id):\n",
    "        # this updates bot state based on target asset_id\n",
    "        # done\n",
    "        tgt_asset_id = int(tgt_asset_id)\n",
    "        if tgt_asset_id != self.cur_asset_id:\n",
    "            if self.cur_asset_id == -1:\n",
    "                self.issue_trades([('Buy', tgt_asset_id)])\n",
    "            elif tgt_asset_id == -1:\n",
    "                self.issue_trades([('Sell', self.cur_asset_id)])\n",
    "            else:\n",
    "                self.issue_trades([('Sell', self.cur_asset_id), ('Buy', tgt_asset_id)])\n",
    "    \n",
    "    def issue_trades(self, orders):\n",
    "        # done\n",
    "        actions = []\n",
    "        for (order_type, asset_id) in orders:\n",
    "            # update the quantities and asset stocks\n",
    "            if order_type == 'Sell':\n",
    "                self.cur_qty = self.cur_qty*self.get_sell_price(asset_id)\n",
    "                self.cur_asset_id = -1\n",
    "            elif order_type == 'Buy':\n",
    "                self.cur_asset_id = asset_id\n",
    "                self.cur_qty = self.cur_qty/self.get_buy_price(asset_id)\n",
    "            # update the orders\n",
    "            actions.append(order_type+self.asset_names[asset_id])\n",
    "            \n",
    "        # update an order book\n",
    "        self.orders.append({\n",
    "                \"time\": self.cur_ts,\n",
    "                \"actions\": actions\n",
    "                })\n",
    "        self.last_trade = self.cur_ts\n",
    "\n",
    "    def get_sell_price(self, asset_id):\n",
    "        return self.last_data[asset_id]['bid']\n",
    "\n",
    "    def get_buy_price(self, asset_id):\n",
    "        return self.last_data[asset_id]['ask']\n",
    "       \n",
    "    def getOrderList(self):\n",
    "        return self.orders\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[7189.   7190.09 7190.09 7190.43 7190.39 7190.33 7190.25 7190.21]\n[7188.89 7190.05 7190.05 7190.05 7190.05 7189.92 7189.92 7189.92]\n[7170.25 7170.25 7170.5  7170.5  7170.5  7170.5  7170.5  7170.5 ]\n[7169.5 7169.5 7169.5 7169.5 7169.5 7169.5 7169.5 7169.5]\n<class 'numpy.ndarray'>\n[[1.050000000000182, -0.17000000000007276, -0.17000000000007276, -0.5100000000002183], [-0.75, -0.75, -1.0, -1.0]]\n1.050000000000182\n0\n0\n"
    }
   ],
   "source": [
    "# \"print unit tests\" for return prediction calculation and descition functions\n",
    "p = idealPredictor(df, ['assetA_ask', 'assetA_bid', 'assetB_ask', 'assetB_bid'], 8)\n",
    "#print(df.head(3))\n",
    "a= p.predict('1577836803078')\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "print(a[2])\n",
    "print(a[3])\n",
    "print(type(a[2]))\n",
    "\n",
    "#a =[]\n",
    "#a.append([101, 102, 103, 104])\n",
    "#a.append([100, 101, 102, 103])\n",
    "#a.append([201, 202, 203, 204])\n",
    "#a.append([200, 201, 202, 203])\n",
    "return_pred = lookAheadTradeReturnPredictorFunc([[a[0], a[1]],[a[2], a[3]]], -1, 4)\n",
    "print(return_pred)\n",
    "(max_return, max_asset, max_time) = lookAheadTradeDescitionMakerFunc(return_pred, [1 for n in range(4)])\n",
    "print(max_return)\n",
    "print(max_asset)\n",
    "print(max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " It took 1.98 seconds. Estimated time left is: 408.76 seconds \n9/214k tamesamples are processed. It took 1.19 seconds. Estimated time left is: 244.55 seconds \n10/214k tamesamples are processed. It took 2.35 seconds. Estimated time left is: 478.96 seconds \n11/214k tamesamples are processed. It took 1.34 seconds. Estimated time left is: 271.94 seconds \n12/214k tamesamples are processed. It took 1.00 seconds. Estimated time left is: 202.31 seconds \n13/214k tamesamples are processed. It took 1.79 seconds. Estimated time left is: 359.02 seconds \n14/214k tamesamples are processed. It took 1.75 seconds. Estimated time left is: 349.75 seconds \n15/214k tamesamples are processed. It took 1.60 seconds. Estimated time left is: 319.06 seconds \n16/214k tamesamples are processed. It took 1.04 seconds. Estimated time left is: 206.21 seconds \n17/214k tamesamples are processed. It took 1.33 seconds. Estimated time left is: 262.41 seconds \n18/214k tamesamples are processed. It took 0.94 seconds. Estimated time left is: 183.32 seconds \n19/214k tamesamples are processed. It took 0.77 seconds. Estimated time left is: 149.39 seconds \n20/214k tamesamples are processed. It took 0.94 seconds. Estimated time left is: 182.72 seconds \n21/214k tamesamples are processed. It took 1.40 seconds. Estimated time left is: 270.58 seconds \n22/214k tamesamples are processed. It took 1.69 seconds. Estimated time left is: 324.02 seconds \n23/214k tamesamples are processed. It took 2.17 seconds. Estimated time left is: 413.75 seconds \n24/214k tamesamples are processed. It took 1.91 seconds. Estimated time left is: 362.83 seconds \n25/214k tamesamples are processed. It took 1.50 seconds. Estimated time left is: 283.19 seconds \n26/214k tamesamples are processed. It took 1.48 seconds. Estimated time left is: 277.49 seconds \n27/214k tamesamples are processed. It took 1.83 seconds. Estimated time left is: 343.02 seconds \n28/214k tamesamples are processed. It took 1.88 seconds. Estimated time left is: 349.28 seconds \n29/214k tamesamples are processed. It took 1.21 seconds. Estimated time left is: 223.81 seconds \n30/214k tamesamples are processed. It took 1.23 seconds. Estimated time left is: 226.31 seconds \n31/214k tamesamples are processed. It took 1.18 seconds. Estimated time left is: 216.76 seconds \n32/214k tamesamples are processed. It took 1.26 seconds. Estimated time left is: 229.88 seconds \n33/214k tamesamples are processed. It took 1.05 seconds. Estimated time left is: 189.86 seconds \n34/214k tamesamples are processed. It took 2.34 seconds. Estimated time left is: 421.14 seconds \n35/214k tamesamples are processed. It took 1.18 seconds. Estimated time left is: 210.76 seconds \n36/214k tamesamples are processed. It took 1.90 seconds. Estimated time left is: 338.14 seconds \n37/214k tamesamples are processed. It took 1.22 seconds. Estimated time left is: 215.15 seconds \n38/214k tamesamples are processed. It took 1.84 seconds. Estimated time left is: 324.60 seconds \n39/214k tamesamples are processed. It took 1.36 seconds. Estimated time left is: 237.79 seconds \n40/214k tamesamples are processed. It took 2.03 seconds. Estimated time left is: 353.55 seconds \n41/214k tamesamples are processed. It took 2.08 seconds. Estimated time left is: 359.17 seconds \n42/214k tamesamples are processed. It took 1.03 seconds. Estimated time left is: 177.98 seconds \n43/214k tamesamples are processed. It took 1.61 seconds. Estimated time left is: 274.49 seconds \n44/214k tamesamples are processed. It took 1.33 seconds. Estimated time left is: 226.92 seconds \n45/214k tamesamples are processed. It took 1.43 seconds. Estimated time left is: 242.00 seconds \n46/214k tamesamples are processed. It took 1.34 seconds. Estimated time left is: 225.68 seconds \n47/214k tamesamples are processed. It took 1.43 seconds. Estimated time left is: 239.46 seconds \n48/214k tamesamples are processed. It took 0.85 seconds. Estimated time left is: 140.46 seconds \n49/214k tamesamples are processed. It took 1.71 seconds. Estimated time left is: 282.41 seconds \n50/214k tamesamples are processed. It took 2.05 seconds. Estimated time left is: 336.34 seconds \n51/214k tamesamples are processed. It took 1.27 seconds. Estimated time left is: 207.46 seconds \n52/214k tamesamples are processed. It took 1.83 seconds. Estimated time left is: 295.77 seconds \n53/214k tamesamples are processed. It took 1.93 seconds. Estimated time left is: 311.02 seconds \n54/214k tamesamples are processed. It took 1.62 seconds. Estimated time left is: 259.49 seconds \n55/214k tamesamples are processed. It took 1.34 seconds. Estimated time left is: 213.79 seconds \n56/214k tamesamples are processed. It took 2.16 seconds. Estimated time left is: 341.73 seconds \n57/214k tamesamples are processed. It took 1.92 seconds. Estimated time left is: 301.95 seconds \n58/214k tamesamples are processed. It took 1.39 seconds. Estimated time left is: 216.75 seconds \n59/214k tamesamples are processed. It took 2.81 seconds. Estimated time left is: 435.84 seconds \n60/214k tamesamples are processed. It took 1.74 seconds. Estimated time left is: 267.68 seconds \n61/214k tamesamples are processed. It took 2.21 seconds. Estimated time left is: 338.37 seconds \n62/214k tamesamples are processed. It took 1.70 seconds. Estimated time left is: 258.44 seconds \n63/214k tamesamples are processed. It took 0.99 seconds. Estimated time left is: 148.77 seconds \n64/214k tamesamples are processed. It took 2.44 seconds. Estimated time left is: 366.05 seconds \n65/214k tamesamples are processed. It took 2.25 seconds. Estimated time left is: 334.73 seconds \n66/214k tamesamples are processed. It took 2.62 seconds. Estimated time left is: 387.44 seconds \n67/214k tamesamples are processed. It took 2.78 seconds. Estimated time left is: 409.20 seconds \n68/214k tamesamples are processed. It took 1.93 seconds. Estimated time left is: 281.44 seconds \n69/214k tamesamples are processed. It took 1.14 seconds. Estimated time left is: 165.68 seconds \n70/214k tamesamples are processed. It took 0.86 seconds. Estimated time left is: 123.46 seconds \n71/214k tamesamples are processed. It took 1.24 seconds. Estimated time left is: 177.39 seconds \n72/214k tamesamples are processed. It took 1.80 seconds. Estimated time left is: 255.49 seconds \n73/214k tamesamples are processed. It took 1.29 seconds. Estimated time left is: 181.42 seconds \n74/214k tamesamples are processed. It took 1.69 seconds. Estimated time left is: 237.05 seconds \n75/214k tamesamples are processed. It took 1.13 seconds. Estimated time left is: 157.71 seconds \n76/214k tamesamples are processed. It took 0.60 seconds. Estimated time left is: 82.53 seconds \n77/214k tamesamples are processed. It took 1.21 seconds. Estimated time left is: 165.14 seconds \n78/214k tamesamples are processed. It took 1.62 seconds. Estimated time left is: 220.49 seconds \n79/214k tamesamples are processed. It took 1.88 seconds. Estimated time left is: 254.11 seconds \n80/214k tamesamples are processed. It took 1.55 seconds. Estimated time left is: 207.32 seconds \n81/214k tamesamples are processed. It took 0.69 seconds. Estimated time left is: 91.60 seconds \n82/214k tamesamples are processed. It took 1.55 seconds. Estimated time left is: 205.19 seconds \n83/214k tamesamples are processed. It took 2.07 seconds. Estimated time left is: 271.36 seconds \n84/214k tamesamples are processed. It took 0.66 seconds. Estimated time left is: 85.93 seconds \n85/214k tamesamples are processed. It took 1.40 seconds. Estimated time left is: 180.34 seconds \n86/214k tamesamples are processed. It took 1.61 seconds. Estimated time left is: 206.13 seconds \n87/214k tamesamples are processed. It took 2.23 seconds. Estimated time left is: 283.44 seconds \n88/214k tamesamples are processed. It took 1.97 seconds. Estimated time left is: 248.75 seconds \n89/214k tamesamples are processed. It took 1.82 seconds. Estimated time left is: 227.86 seconds \n90/214k tamesamples are processed. It took 1.90 seconds. Estimated time left is: 235.72 seconds \n91/214k tamesamples are processed. It took 1.73 seconds. Estimated time left is: 212.47 seconds \n92/214k tamesamples are processed. It took 2.27 seconds. Estimated time left is: 276.75 seconds \n93/214k tamesamples are processed. It took 2.25 seconds. Estimated time left is: 272.12 seconds \n94/214k tamesamples are processed. It took 2.41 seconds. Estimated time left is: 288.65 seconds \n95/214k tamesamples are processed. It took 2.84 seconds. Estimated time left is: 337.53 seconds \n96/214k tamesamples are processed. It took 2.73 seconds. Estimated time left is: 322.33 seconds \n97/214k tamesamples are processed. It took 2.28 seconds. Estimated time left is: 266.66 seconds \n98/214k tamesamples are processed. It took 0.89 seconds. Estimated time left is: 102.85 seconds \n99/214k tamesamples are processed. It took 0.91 seconds. Estimated time left is: 104.41 seconds \n100/214k tamesamples are processed. It took 1.30 seconds. Estimated time left is: 147.78 seconds \n101/214k tamesamples are processed. It took 2.07 seconds. Estimated time left is: 233.62 seconds \n102/214k tamesamples are processed. It took 1.74 seconds. Estimated time left is: 195.04 seconds \n103/214k tamesamples are processed. It took 1.28 seconds. Estimated time left is: 141.54 seconds \n104/214k tamesamples are processed. It took 0.61 seconds. Estimated time left is: 67.11 seconds \n105/214k tamesamples are processed. It took 0.96 seconds. Estimated time left is: 105.09 seconds \n106/214k tamesamples are processed. It took 2.13 seconds. Estimated time left is: 230.20 seconds \n107/214k tamesamples are processed. It took 1.72 seconds. Estimated time left is: 184.25 seconds \n108/214k tamesamples are processed. It took 1.29 seconds. Estimated time left is: 136.69 seconds \n109/214k tamesamples are processed. It took 1.75 seconds. Estimated time left is: 183.65 seconds \n110/214k tamesamples are processed. It took 1.45 seconds. Estimated time left is: 150.35 seconds \n111/214k tamesamples are processed. It took 0.80 seconds. Estimated time left is: 82.54 seconds \n112/214k tamesamples are processed. It took 2.09 seconds. Estimated time left is: 212.81 seconds \n113/214k tamesamples are processed. It took 1.13 seconds. Estimated time left is: 114.61 seconds \n114/214k tamesamples are processed. It took 1.88 seconds. Estimated time left is: 188.36 seconds \n115/214k tamesamples are processed. It took 1.05 seconds. Estimated time left is: 104.09 seconds \n116/214k tamesamples are processed. It took 1.92 seconds. Estimated time left is: 188.59 seconds \n117/214k tamesamples are processed. It took 2.31 seconds. Estimated time left is: 224.06 seconds \n118/214k tamesamples are processed. It took 1.70 seconds. Estimated time left is: 163.28 seconds \n119/214k tamesamples are processed. It took 2.34 seconds. Estimated time left is: 222.57 seconds \n120/214k tamesamples are processed. It took 1.83 seconds. Estimated time left is: 172.44 seconds \n121/214k tamesamples are processed. It took 1.35 seconds. Estimated time left is: 125.63 seconds \n122/214k tamesamples are processed. It took 2.00 seconds. Estimated time left is: 184.03 seconds \n123/214k tamesamples are processed. It took 1.58 seconds. Estimated time left is: 143.81 seconds \n124/214k tamesamples are processed. It took 1.69 seconds. Estimated time left is: 152.02 seconds \n125/214k tamesamples are processed. It took 1.41 seconds. Estimated time left is: 125.25 seconds \n126/214k tamesamples are processed. It took 1.60 seconds. Estimated time left is: 140.96 seconds \n127/214k tamesamples are processed. It took 2.24 seconds. Estimated time left is: 194.66 seconds \n128/214k tamesamples are processed. It took 2.05 seconds. Estimated time left is: 176.41 seconds \n129/214k tamesamples are processed. It took 1.82 seconds. Estimated time left is: 154.32 seconds \n130/214k tamesamples are processed. It took 1.50 seconds. Estimated time left is: 125.81 seconds \n131/214k tamesamples are processed. It took 1.63 seconds. Estimated time left is: 135.63 seconds \n132/214k tamesamples are processed. It took 2.40 seconds. Estimated time left is: 197.05 seconds \n133/214k tamesamples are processed. It took 3.16 seconds. Estimated time left is: 256.21 seconds \n134/214k tamesamples are processed. It took 2.00 seconds. Estimated time left is: 160.32 seconds \n135/214k tamesamples are processed. It took 2.03 seconds. Estimated time left is: 160.02 seconds \n136/214k tamesamples are processed. It took 1.68 seconds. Estimated time left is: 131.14 seconds \n137/214k tamesamples are processed. It took 1.19 seconds. Estimated time left is: 91.50 seconds \n138/214k tamesamples are processed. It took 1.02 seconds. Estimated time left is: 77.28 seconds \n139/214k tamesamples are processed. It took 0.80 seconds. Estimated time left is: 59.90 seconds \n140/214k tamesamples are processed. It took 1.54 seconds. Estimated time left is: 113.74 seconds \n141/214k tamesamples are processed. It took 1.72 seconds. Estimated time left is: 125.87 seconds \n142/214k tamesamples are processed. It took 1.29 seconds. Estimated time left is: 92.97 seconds \n143/214k tamesamples are processed. It took 2.68 seconds. Estimated time left is: 190.34 seconds \n144/214k tamesamples are processed. It took 1.95 seconds. Estimated time left is: 136.52 seconds \n145/214k tamesamples are processed. It took 1.53 seconds. Estimated time left is: 105.88 seconds \n146/214k tamesamples are processed. It took 1.91 seconds. Estimated time left is: 129.98 seconds \n147/214k tamesamples are processed. It took 1.80 seconds. Estimated time left is: 120.37 seconds \n148/214k tamesamples are processed. It took 2.32 seconds. Estimated time left is: 153.14 seconds \n149/214k tamesamples are processed. It took 2.80 seconds. Estimated time left is: 181.75 seconds \n150/214k tamesamples are processed. It took 1.33 seconds. Estimated time left is: 85.33 seconds \n151/214k tamesamples are processed. It took 1.69 seconds. Estimated time left is: 106.42 seconds \n152/214k tamesamples are processed. It took 1.77 seconds. Estimated time left is: 109.90 seconds \n153/214k tamesamples are processed. It took 2.57 seconds. Estimated time left is: 156.76 seconds \n154/214k tamesamples are processed. It took 2.04 seconds. Estimated time left is: 122.55 seconds \n155/214k tamesamples are processed. It took 1.91 seconds. Estimated time left is: 112.70 seconds \n156/214k tamesamples are processed. It took 1.19 seconds. Estimated time left is: 69.20 seconds \n157/214k tamesamples are processed. It took 1.51 seconds. Estimated time left is: 85.89 seconds \n158/214k tamesamples are processed. It took 2.46 seconds. Estimated time left is: 137.85 seconds \n159/214k tamesamples are processed. It took 2.19 seconds. Estimated time left is: 120.51 seconds \n160/214k tamesamples are processed. It took 2.61 seconds. Estimated time left is: 141.15 seconds \n161/214k tamesamples are processed. It took 2.01 seconds. Estimated time left is: 106.46 seconds \n162/214k tamesamples are processed. It took 3.51 seconds. Estimated time left is: 182.59 seconds \n163/214k tamesamples are processed. It took 3.63 seconds. Estimated time left is: 185.04 seconds \n164/214k tamesamples are processed. It took 2.20 seconds. Estimated time left is: 110.12 seconds \n165/214k tamesamples are processed. It took 2.40 seconds. Estimated time left is: 117.70 seconds \n166/214k tamesamples are processed. It took 2.72 seconds. Estimated time left is: 130.46 seconds \n167/214k tamesamples are processed. It took 3.20 seconds. Estimated time left is: 150.58 seconds \n168/214k tamesamples are processed. It took 2.79 seconds. Estimated time left is: 128.18 seconds \n169/214k tamesamples are processed. It took 2.39 seconds. Estimated time left is: 107.52 seconds \n170/214k tamesamples are processed. It took 2.22 seconds. Estimated time left is: 97.55 seconds \n171/214k tamesamples are processed. It took 1.93 seconds. Estimated time left is: 82.80 seconds \n172/214k tamesamples are processed. It took 1.63 seconds. Estimated time left is: 68.44 seconds \n173/214k tamesamples are processed. It took 1.36 seconds. Estimated time left is: 55.76 seconds \n174/214k tamesamples are processed. It took 2.46 seconds. Estimated time left is: 98.29 seconds \n175/214k tamesamples are processed. It took 1.22 seconds. Estimated time left is: 47.47 seconds \n176/214k tamesamples are processed. It took 1.49 seconds. Estimated time left is: 56.69 seconds \n177/214k tamesamples are processed. It took 2.42 seconds. Estimated time left is: 89.55 seconds \n178/214k tamesamples are processed. It took 1.68 seconds. Estimated time left is: 60.66 seconds \n179/214k tamesamples are processed. It took 2.16 seconds. Estimated time left is: 75.77 seconds \n180/214k tamesamples are processed. It took 2.67 seconds. Estimated time left is: 90.86 seconds \n181/214k tamesamples are processed. It took 2.26 seconds. Estimated time left is: 74.64 seconds \n182/214k tamesamples are processed. It took 2.11 seconds. Estimated time left is: 67.43 seconds \n183/214k tamesamples are processed. It took 2.03 seconds. Estimated time left is: 62.82 seconds \n184/214k tamesamples are processed. It took 2.21 seconds. Estimated time left is: 66.29 seconds \n185/214k tamesamples are processed. It took 2.42 seconds. Estimated time left is: 70.14 seconds \n186/214k tamesamples are processed. It took 1.95 seconds. Estimated time left is: 54.68 seconds \n187/214k tamesamples are processed. It took 2.32 seconds. Estimated time left is: 62.68 seconds \n188/214k tamesamples are processed. It took 2.06 seconds. Estimated time left is: 53.69 seconds \n189/214k tamesamples are processed. It took 2.26 seconds. Estimated time left is: 56.60 seconds \n190/214k tamesamples are processed. It took 1.29 seconds. Estimated time left is: 30.87 seconds \n191/214k tamesamples are processed. It took 1.62 seconds. Estimated time left is: 37.20 seconds \n192/214k tamesamples are processed. It took 2.35 seconds. Estimated time left is: 51.60 seconds \n193/214k tamesamples are processed. It took 2.01 seconds. Estimated time left is: 42.22 seconds \n194/214k tamesamples are processed. It took 2.61 seconds. Estimated time left is: 52.12 seconds \n195/214k tamesamples are processed. It took 1.07 seconds. Estimated time left is: 20.35 seconds \n196/214k tamesamples are processed. It took 2.49 seconds. Estimated time left is: 44.79 seconds \n197/214k tamesamples are processed. It took 1.60 seconds. Estimated time left is: 27.27 seconds \n198/214k tamesamples are processed. It took 1.38 seconds. Estimated time left is: 22.00 seconds \n199/214k tamesamples are processed. It took 0.78 seconds. Estimated time left is: 11.75 seconds \n200/214k tamesamples are processed. It took 3.00 seconds. Estimated time left is: 42.03 seconds \n201/214k tamesamples are processed. It took 1.95 seconds. Estimated time left is: 25.38 seconds \n202/214k tamesamples are processed. It took 1.74 seconds. Estimated time left is: 20.92 seconds \n203/214k tamesamples are processed. It took 1.41 seconds. Estimated time left is: 15.46 seconds \n204/214k tamesamples are processed. It took 1.87 seconds. Estimated time left is: 18.70 seconds \n205/214k tamesamples are processed. It took 2.57 seconds. Estimated time left is: 23.10 seconds \n206/214k tamesamples are processed. It took 2.46 seconds. Estimated time left is: 19.65 seconds \n207/214k tamesamples are processed. It took 2.10 seconds. Estimated time left is: 14.73 seconds \n208/214k tamesamples are processed. It took 2.03 seconds. Estimated time left is: 12.16 seconds \n209/214k tamesamples are processed. It took 1.64 seconds. Estimated time left is: 8.19 seconds \n210/214k tamesamples are processed. It took 2.37 seconds. Estimated time left is: 9.48 seconds \n211/214k tamesamples are processed. It took 1.77 seconds. Estimated time left is: 5.30 seconds \n212/214k tamesamples are processed. It took 2.24 seconds. Estimated time left is: 4.49 seconds \n213/214k tamesamples are processed. It took 1.92 seconds. Estimated time left is: 1.92 seconds \n"
    }
   ],
   "source": [
    "# Auxilary functions to run the bot\n",
    "def read_tick(df):\n",
    "    for i, row in df.iterrows():\n",
    "        tick = {'timestamp':row['ts'],\n",
    "                'assets':[  {'ask':row['assetA_ask'],'bid':row['assetA_bid']}, \n",
    "                            {'ask':row['assetB_ask'],'bid':row['assetB_bid']}\n",
    "                        ]\n",
    "                }\n",
    "        yield tick\n",
    "\n",
    "\n",
    "\n",
    "# Creating the bot\n",
    "ticks_per_trade_delay = 60\n",
    "trade_delay = 30\n",
    "asset_names = ['A', 'B']\n",
    "idealP = idealPredictor(df, ['assetA_ask', 'assetA_bid', 'assetB_ask', 'assetB_bid'], ticks_per_trade_delay*2)\n",
    "bot = tradingBot(asset_names, trade_delay, ticks_per_trade_delay, idealP, lookAheadTradeReturnPredictorFunc, lookAheadTradeDescitionMakerFunc)\n",
    "\n",
    "# Running the simulation\n",
    "i = 0\n",
    "j = 0\n",
    "total_kts = round(len(df)/1000)\n",
    "start = time.time()\n",
    "total_process_time = 0\n",
    "for t in read_tick(df):\n",
    "    i=i+1\n",
    "    bot.compute_tick(t['timestamp'], t['assets'])\n",
    "    if i == 1000:\n",
    "        end = time.time()\n",
    "        delta = end-start\n",
    "        total_process_time = total_process_time + delta\n",
    "        avg_k_process_time = float(total_process_time)/j\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        j=j+1\n",
    "        print(f'{j}/{total_kts}k tamesamples are processed. It took {delta:.2f} seconds. Estimated time left is: {avg_k_process_time*(total_kts-j):.2f} seconds ')\n",
    "\n",
    "print(f'Done! All {total_kts}k tamesamples were processed')\n",
    "\n",
    "output = bot.getOrderList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(output)\n",
    "\n",
    "import json\n",
    "with open('IdealPredictorOutput.json', 'w') as fp:\n",
    "    json.dump(output, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}